
# db ë˜ëŠ” ìƒˆ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ í†µí•©ì ìœ¼ë¡œ main ëŒ€ì‹œë³´ë“œì— í•„ìš”í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª¨ë“ˆ


import requests
from bs4 import BeautifulSoup
from dbmanage_News import BillNews
from dbmanage_NewsReact import SessionLocal, NewsSentiment
from dash_news_app import create_dash_app_from_result
import urllib.request
import urllib.parse
import json
from collections import defaultdict
from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.orm import sessionmaker, declarative_base
from dbmanage_News import Bill


# ìµœì‹ ë²•ì•ˆì •ë³´
# ì†ë„ê°€ ë¹ ë¥´ê³ , ì‹¤ì‹œê°„ ì •ë³´ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ main ì‹¤í–‰ ì‹œë§ˆë‹¤ ì¶”ì¶œí•˜ë„ë¡ í•¨ 
def truncate(text, limit=10):
    return text[:limit] + "..." if len(text) > limit else text

def get_latest_laws(n=3):
    url = "https://www.law.go.kr/LSW/nwRvsLsPop.do?p_epubdt="
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    response = requests.get(url, headers=headers)
    response.encoding = "utf-8"
    soup = BeautifulSoup(response.text, "html.parser")

    tbody = soup.select_one("table.tbl3 > tbody")
    rows = tbody.find_all("tr")

    law_list = []

    for row in rows[:n]:  # ìƒìœ„ nê°œë§Œ ì¶”ì¶œ
        columns = row.find_all("td")
        law_title_tag = columns[1].find("a")
        law_title = law_title_tag['title'].strip()

        # ì „ì²´ ë§í¬ ì¡°í•©
        href = law_title_tag['href'].strip()
        if not href.startswith("/"):
            href = "/" + href  # ìŠ¬ë˜ì‹œ ìë™ ë³´ì •

        detail_link = "https://www.law.go.kr" + href


        department = columns[2].get_text(strip=True)
        revision_type = columns[3].get_text(strip=True)
        proclaim_date = columns[6].get_text(strip=True)
        enforce_date = columns[7].get_text(strip=True)

        law_info = {
            "ë²•ì•ˆëª…": law_title,
            "ë²•ì•ˆëª…_truncated": truncate(law_title, 10),
            "ì†Œê´€ë¶€ì„œ": department,
            "ì œì •/ê°œì •êµ¬ë¶„": revision_type,
            "ê³µí¬ì¼ì": proclaim_date,
            "ì‹œí–‰ì¼ì": enforce_date,
            "ìƒì„¸ë§í¬": detail_link
        }

        law_list.append(law_info)

    return law_list


# ë©”ì¸-ì—¬ë¡ ë¶„ì„ ë¸”ëŸ­
def get_latest_news():
    session = SessionLocal()
    try:
        sentiment = session.query(NewsSentiment).order_by(NewsSentiment.analyzed_at.desc()).first()

        if sentiment:
            news = session.query(BillNews).filter_by(bill_id=sentiment.bill_id).first()

            pos = sentiment.positive_count or 0
            neg = sentiment.negative_count or 0
            neu = sentiment.neutral_count or 0
            total_comments = pos + neg + neu

            sentiment_data = {
                "title": (sentiment.title[:10] + "â€¦") if news and len(sentiment.title) > 10 else (sentiment.title if news else "ê¸°ì‚¬ ì œëª© ì—†ìŒ"),
                "news_bill_id": sentiment.id,
                "news_title": (news.news_title[:13] + "â€¦") if news and len(news.news_title) > 13 else (news.news_title if news else "ê¸°ì‚¬ ì œëª© ì—†ìŒ"),
                "news_body": (news.body[:200] + "â€¦") if news and len(news.body) > 200 else (news.body if news else "ê¸°ì‚¬ ë³¸ë¬¸ ì—†ìŒ"),
                "news_link": news.news_url if news else None,
                "comments": total_comments,
                "positive_count": pos,
                "negative_count": neg,
                "neutral_count": neu,
            }
            return sentiment_data
        else:
            return None
    except Exception as e:
        print(f"[ERROR] get_latest_news: {e}")
        return None
    finally:
        session.close()




#ë²•ì•ˆ ë­í‚¹
from dbmanage_News import Bill
from dbmanage_ranking import TrendingBill, Base, init_ranking_db  


# ------------------- DB ì—°ê²° -------------------
def get_session(db_path="sqlite:///bills.db"):
    engine = create_engine(db_path)
    Session = sessionmaker(bind=engine)
    return Session()

# ------------------- ë²•ì•ˆëª… ë¶ˆëŸ¬ì˜¤ê¸° -------------------
def get_law_keywords(session):
    bills = session.query(Bill.title).all()
    return [title for (title,) in bills]

# ------------------- ë„¤ì´ë²„ ë‰´ìŠ¤ API -------------------
client_id = "CKb4pAJ84D6tVcCvpjka"
client_secret = "5PucVvnteo"

headers = {
    "X-Naver-Client-Id": client_id,
    "X-Naver-Client-Secret": client_secret
}
base_url = "https://openapi.naver.com/v1/search/news.json"

def get_news_articles(query, start):
    url = f"{base_url}?query={urllib.parse.quote(query)}&display=100&start={start}&sort=date"
    request = urllib.request.Request(url, headers=headers)
    response = urllib.request.urlopen(request)
    if response.getcode() == 200:
        return json.loads(response.read().decode("utf-8"))
    else:
        print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨: HTTP Error {response.getcode()}")
        return None

# ------------------- í‚¤ì›Œë“œ ì–¸ê¸‰ ìˆ˜ ì„¸ê¸° -------------------
def count_keyword_mentions(news_items, keyword):
    return sum(
        (item["title"] + item["description"]).lower().count(keyword.lower())
        for item in news_items
    )

# ------------------- íŠ¸ë Œë”© í‚¤ì›Œë“œ ê³„ì‚° -------------------
def calculate_trending_keywords(session):
    keywords = get_law_keywords(session)
    keyword_counts = defaultdict(int)

    for kw in keywords:
        print(f"ğŸ” '{kw}' í‚¤ì›Œë“œ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        result = get_news_articles(kw, 1)  # ë‰´ìŠ¤ 100ê°œë§Œ
        if result and "items" in result:
            keyword_counts[kw] += count_keyword_mentions(result["items"], kw)

    return keyword_counts

# ------------------- ë­í‚¹ ì¶œë ¥ -------------------
def display_top_keywords(keyword_counts):
    sorted_counts = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
    print("ğŸ“Š ìµœê·¼ ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ í™”ì œ ë²•ì•ˆ TOP 5")
    for i, (kw, count) in enumerate(sorted_counts[:5], 1):
        print(f"{i}. {kw} - ì–¸ê¸‰ {count}íšŒ")
    return sorted_counts[:5]

# âœ… ë­í‚¹ ì €ì¥ í•¨ìˆ˜
def save_ranking_to_db(session, sorted_counts):
    session.query(TrendingBill).delete()
    for rank, (kw, count) in enumerate(sorted_counts[:5], 1):
        session.add(TrendingBill(title=kw, rank=rank, count=count))
    session.commit()
    print("âœ… ë­í‚¹ DB ì €ì¥ ì™„ë£Œ")

# âœ… ë­í‚¹ ì¡°íšŒ í•¨ìˆ˜
def get_ranking(session):
    return session.query(TrendingBill).order_by(TrendingBill.rank).all()

# ------------------- ë©”ì¸ -------------------
def main():
    init_ranking_db()  # í…Œì´ë¸” ìƒì„±
    session = get_session()

    keyword_counts = calculate_trending_keywords(session)
    top_5 = display_top_keywords(keyword_counts)
    save_ranking_to_db(session, top_5)
    session.close()

if __name__ == "__main__":
        main()