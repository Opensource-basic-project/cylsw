
# db ë˜ëŠ” ìƒˆ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ í†µí•©ì ìœ¼ë¡œ main ëŒ€ì‹œë³´ë“œì— í•„ìš”í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª¨ë“ˆ


import requests
from bs4 import BeautifulSoup
from dbmanage_News import BillNews
from dbmanage_NewsReact import SessionLocal_News, NewsSentiment
from dash_news_app import create_dash_app_from_result
import urllib.request
import urllib.parse
import json
from collections import defaultdict
from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.orm import sessionmaker, declarative_base
from dbmanage_News import Bill

from db import (
    SessionLocal, 
    PlenaryBill, 
    LegislationNotice, 
    EndedLegislationNotice, 
    ForeignLawTrend,
    ForeignLawExample
    )

# ìµœì‹ ë²•ì•ˆì •ë³´
# ì†ë„ê°€ ë¹ ë¥´ê³ , ì‹¤ì‹œê°„ ì •ë³´ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ main ì‹¤í–‰ ì‹œë§ˆë‹¤ ì¶”ì¶œí•˜ë„ë¡ í•¨ (js ê°€ ì•„ë‹ˆë¼ì„œ ë¹¨ë¦¬ í¬ë¡¤ë§ê°€ëŠ¥)
def truncate(text, limit=10):
    return text[:limit] + "..." if len(text) > limit else text

def get_latest_laws(n=3):
    url = "https://www.law.go.kr/LSW/nwRvsLsPop.do?p_epubdt="
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    response = requests.get(url, headers=headers)
    response.encoding = "utf-8"
    soup = BeautifulSoup(response.text, "html.parser")

    tbody = soup.select_one("table.tbl3 > tbody")
    rows = tbody.find_all("tr")

    law_list = []

    for row in rows[:n]:  # ìƒìœ„ nê°œë§Œ ì¶”ì¶œ
        columns = row.find_all("td")
        law_title_tag = columns[1].find("a")
        law_title = law_title_tag['title'].strip()

        # ì „ì²´ ë§í¬ ì¡°í•©
        href = law_title_tag['href'].strip()
        if not href.startswith("/"):
            href = "/" + href  # ìŠ¬ë˜ì‹œ ìë™ ë³´ì •

        detail_link = "https://www.law.go.kr" + href


        department = columns[2].get_text(strip=True)
        revision_type = columns[3].get_text(strip=True)
        proclaim_date = columns[6].get_text(strip=True)
        enforce_date = columns[7].get_text(strip=True)

        law_info = {
            "ë²•ì•ˆëª…": law_title,
            "ë²•ì•ˆëª…_truncated": truncate(law_title, 10),
            "ì†Œê´€ë¶€ì„œ": department,
            "ì œì •/ê°œì •êµ¬ë¶„": revision_type,
            "ê³µí¬ì¼ì": proclaim_date,
            "ì‹œí–‰ì¼ì": enforce_date,
            "ìƒì„¸ë§í¬": detail_link
        }

        law_list.append(law_info)

    return law_list


# ë©”ì¸-ë³¸íšŒì˜ ë²•ì•ˆì •ë³´ ë¸”ëŸ­ (6ê°œ)

def get_plenary_info_main():
    session = SessionLocal()
    try:
        # ê°€ì¥ ë¨¼ì € ì €ì¥ëœ ë²•ì•ˆ 6ê±´ ì¡°íšŒ ( propose_dt ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ)
        plenary_list = session.query(PlenaryBill).order_by(PlenaryBill.propose_dt.desc()).limit(6).all()

        plenary_mlist = []
        for plenary in plenary_list:
            item = {
                "bill_title": plenary.bill_name or "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "propose_date": plenary.propose_dt or "-",
                "proc_result": plenary.plenary_vote_result or plenary.proc_result_cd or "-",
                "proposer": plenary.proposer or "-",
            }
            plenary_mlist.append(item)

        return plenary_mlist

    finally:
        session.close()



# ë©”ì¸-ì…ë²•ì˜ˆê³  ë¦¬ìŠ¤íŠ¸ ë¸”ëŸ­ (6ê°œ)

def get_notice_info_main():
    session = SessionLocal()
    try:
        # ì§„í–‰ì¤‘ ì…ë²•ì˜ˆê³  ì¡°íšŒ (ìµœì‹ ìˆœ)
        ongoing = session.query(LegislationNotice).order_by(
            LegislationNotice.notice_period.desc()
        ).limit(7).all()
        
        # ì¢…ë£Œëœ ì…ë²•ì˜ˆê³  ì¡°íšŒ (ìµœì‹ ìˆœ)
        ended = session.query(EndedLegislationNotice).order_by(
            EndedLegislationNotice.notice_period.desc()
        ).limit(7).all()

        # ìƒíƒœ êµ¬ë¶„ í•„ë“œ ì¶”ê°€
        combined_list = []
        for notice in ongoing:
            combined_list.append({
                **notice_to_dict(notice),
                "status": "ongoing"  # ì§„í–‰ì¤‘ í‘œì‹œ
            })
            
        for notice in ended:
            combined_list.append({
                **notice_to_dict(notice),
                "status": "ended"  # ì¢…ë£Œ í‘œì‹œ
            })

        # ìµœì¢… ì •ë ¬ (notice_period ê¸°ì¤€)
        combined_list.sort(
            key=lambda x: x["notice_period"] or "",
            reverse=True
        )

        return combined_list[:7]  # ìƒìœ„ 6ê°œ ë°˜í™˜

    finally:
        session.close()

def notice_to_dict(notice):
    """ê³µí†µ í•„ë“œ ë³€í™˜ í•¨ìˆ˜"""
    return {
        "bill_name": notice.bill_name or "ë°ì´í„° ì—†ìŒ",
        "notice_period": notice.notice_period or "-",
        "proposer": notice.proposer or "-",
        "announce_dt": notice.announce_dt or "-",
        "link_url": notice.link_url or "#"
    }




# ë©”ì¸-ì—¬ë¡ ë¶„ì„ ë¸”ëŸ­
def get_latest_news():
    session = SessionLocal_News()
    try:
        sentiment = session.query(NewsSentiment).order_by(NewsSentiment.analyzed_at.asc()).first() # ë‰´ìŠ¤ê¸°ì‚¬ ì •ë ¬ 1page ë¡œ ë§¤ì¹­

        if sentiment:
            news = session.query(BillNews).filter_by(bill_id=sentiment.bill_id).first()

            pos = sentiment.positive_count or 0
            neg = sentiment.negative_count or 0
            neu = sentiment.neutral_count or 0
            total_comments = pos + neg + neu

            sentiment_data = {
                "title": (sentiment.title[:8] + "â€¦") if news and len(sentiment.title) > 10 else (sentiment.title if news else "ê¸°ì‚¬ ì œëª© ì—†ìŒ"),
                "news_bill_id": sentiment.id,
                "news_title": (news.news_title[:13] + "â€¦") if news and len(news.news_title) > 13 else (news.news_title if news else "ê¸°ì‚¬ ì œëª© ì—†ìŒ"),
                "news_body": (news.body[:200] + "â€¦") if news and len(news.body) > 200 else (news.body if news else "ê¸°ì‚¬ ë³¸ë¬¸ ì—†ìŒ"),
                "news_link": news.news_url if news else None,
                "comments": total_comments,
                "positive_count": pos,
                "negative_count": neg,
                "neutral_count": neu,
            }
            return sentiment_data 
        else:
            return None
    except Exception as e:
        print(f"[ERROR] get_latest_news: {e}")
        return None
    finally:
        session.close()



# ë©”ì¸-êµ­ì™¸ì…ë²• ë¸”ëŸ­
def get_foreign_info_main():
    session = SessionLocal()
    try:
        # ì£¼ìš”êµ­ ì…ë²•ë¡€ - ìµœì‹ ìˆœ 1ê°œ
        foreign_examples = (
            session.query(ForeignLawExample)
            .order_by(ForeignLawExample.issue_date.desc())
            .limit(1)
            .all()
        )
        
        # ì£¼ìš”êµ­ ì…ë²•ë™í–¥ - ìµœì‹ ìˆœ 1ê°œ  
        foreign_trends = (
            session.query(ForeignLawTrend)
            .order_by(ForeignLawTrend.procl_date.desc())
            .limit(1)
            .all()
        )

        # ì…ë²•ë¡€ ë°ì´í„° í¬ë§·íŒ…
        examples_list = []
        for example in foreign_examples:
            item = {
                "title": example.title or "ì œëª© ì—†ìŒ",
                "issue_date": example.issue_date or "-",
                "rel_law": example.rel_law or "-",
                "asc_name": example.asc_name or "-",
                "proposal_text": example.proposal_text or "",
                "detail_url": example.detail_url or "#"
            }
            examples_list.append(item)

        # ì…ë²•ë™í–¥ ë°ì´í„° í¬ë§·íŒ…
        trends_list = []
        for trend in foreign_trends:
            item = {
                "title": trend.title or "ì œëª© ì—†ìŒ",
                "procl_date": trend.procl_date or "-",
                "nation_name": trend.nation_name or "-",
                "org_law_name": trend.org_law_name or "-",
                "proposal_text": trend.proposal_text or "",
                "detail_url": trend.detail_url or "#"
            }
            trends_list.append(item)

        return examples_list, trends_list

    finally:
        session.close()












#ë²•ì•ˆ ë­í‚¹ 
from dbmanage_News import Bill
from dbmanage_ranking import TrendingBill, Base, init_ranking_db  


# ------------------- DB ì—°ê²° -------------------
def get_session(db_path="sqlite:///bills.db"):
    engine = create_engine(db_path)
    Session = sessionmaker(bind=engine)
    return Session()

# ------------------- ë²•ì•ˆëª… ë¶ˆëŸ¬ì˜¤ê¸° -------------------
def get_law_keywords(session):
    bills = session.query(Bill.title).all()
    return [title for (title,) in bills]

# ------------------- ë„¤ì´ë²„ ë‰´ìŠ¤ API -------------------
client_id = "CKb4pAJ84D6tVcCvpjka"
client_secret = "5PucVvnteo"

headers = {
    "X-Naver-Client-Id": client_id,
    "X-Naver-Client-Secret": client_secret
}
base_url = "https://openapi.naver.com/v1/search/news.json"

def get_news_articles(query, start):
    url = f"{base_url}?query={urllib.parse.quote(query)}&display=100&start={start}&sort=date"
    request = urllib.request.Request(url, headers=headers)
    response = urllib.request.urlopen(request)
    if response.getcode() == 200:
        return json.loads(response.read().decode("utf-8"))
    else:
        print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨: HTTP Error {response.getcode()}")
        return None

# ------------------- í‚¤ì›Œë“œ ì–¸ê¸‰ ìˆ˜ ì„¸ê¸° -------------------
def count_keyword_mentions(news_items, keyword):
    return sum(
        (item["title"] + item["description"]).lower().count(keyword.lower())
        for item in news_items
    )

# ------------------- íŠ¸ë Œë”© í‚¤ì›Œë“œ ê³„ì‚° -------------------
def calculate_trending_keywords(session):
    keywords = get_law_keywords(session)
    keyword_counts = defaultdict(int)

    for kw in keywords:
        print(f"ğŸ” '{kw}' í‚¤ì›Œë“œ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        result = get_news_articles(kw, 1)  # ë‰´ìŠ¤ 100ê°œë§Œ
        if result and "items" in result:
            keyword_counts[kw] += count_keyword_mentions(result["items"], kw)

    return keyword_counts

# ------------------- ë­í‚¹ ì¶œë ¥ -------------------
def display_top_keywords(keyword_counts):
    sorted_counts = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
    print("ğŸ“Š ìµœê·¼ ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ í™”ì œ ë²•ì•ˆ TOP 5")
    for i, (kw, count) in enumerate(sorted_counts[:5], 1):
        print(f"{i}. {kw} - ì–¸ê¸‰ {count}íšŒ")
    return sorted_counts[:5]

# âœ… ë­í‚¹ ì €ì¥ í•¨ìˆ˜
def save_ranking_to_db(session, sorted_counts):
    session.query(TrendingBill).delete()
    for rank, (kw, count) in enumerate(sorted_counts[:5], 1):
        session.add(TrendingBill(title=kw, rank=rank, count=count))
    session.commit()
    print("âœ… ë­í‚¹ DB ì €ì¥ ì™„ë£Œ")

# âœ… ë­í‚¹ ì¡°íšŒ í•¨ìˆ˜
def get_ranking(session):
    return session.query(TrendingBill).order_by(TrendingBill.rank).all()

# ------------------- ë©”ì¸ -------------------
def main():
    init_ranking_db()  # í…Œì´ë¸” ìƒì„±
    session = get_session()

    keyword_counts = calculate_trending_keywords(session)
    top_5 = display_top_keywords(keyword_counts)
    save_ranking_to_db(session, top_5)
    session.close()

if __name__ == "__main__": # ë²•ì•ˆë­í‚¹ í…ŒìŠ¤íŠ¸ë©”ì¸
        main()