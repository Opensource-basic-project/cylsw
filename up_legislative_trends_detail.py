from db import SessionLocal, ForeignLawTrend
import requests
from bs4 import BeautifulSoup
import time

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

def crawl_foreign_description(link_url: str):
    try:
        response = requests.get(link_url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        meta_tag = soup.find("meta", attrs={"name": "description"})
        if meta_tag and "content" in meta_tag.attrs:
            return meta_tag["content"].replace("<br/>", "<br>").strip()
    except Exception as e:
        print(f"[ì—ëŸ¬] {link_url} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
    return None

def update_foreign_law_descriptions():
    db = SessionLocal()
    try:
        targets = db.query(ForeignLawTrend).filter(
            (ForeignLawTrend.procl_date != None) &
            ((ForeignLawTrend.asc_info == None) | (ForeignLawTrend.asc_info == "")) |
            ((ForeignLawTrend.detail_url != None) & ((ForeignLawTrend.proposal_text == None) | (ForeignLawTrend.proposal_text == "")))
        ).all()

        for law in targets:
            if law.detail_url:
                print(f"[ì™¸êµ­ì…ë²•] ğŸ“„ {law.title} - ì„¤ëª… í¬ë¡¤ë§ ì¤‘...")
                detail = crawl_foreign_description(law.detail_url)
                if not detail:
                    print(f"[ì™¸êµ­ì…ë²•] âŒ ì¬ì‹œë„...")
                    time.sleep(1)
                    detail = crawl_foreign_description(law.detail_url)
                if detail:
                    law.proposal_text = detail
                else:
                    print(f"[ì™¸êµ­ì…ë²•] ğŸš« ì‹¤íŒ¨: {law.detail_url}")
                time.sleep(1)
        db.commit()
        print("[ì™¸êµ­ì…ë²•] âœ… ì„¤ëª… ê°±ì‹  ì™„ë£Œ")
    finally:
        db.close()

if __name__ == "__main__":
    update_foreign_law_descriptions()
